{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "real-world-NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9u+iC3uV4cqCZ6D7Lulf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chediak/CLIP/blob/main/real_world_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allennlp==2.5.0\n",
        "!pip install allennlp-models==2.5.0\n",
        "!git clone https://github.com/mhagiwara/realworldnlp.git\n",
        "%cd realworldnlp"
      ],
      "metadata": {
        "id": "phYRaKOHrv_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.data_loaders import MultiProcessDataLoader\n",
        "from allennlp.data.samplers import BucketBatchSampler\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.training import GradientDescentTrainer\n",
        "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
        "from allennlp_models.classification.dataset_readers.stanford_sentiment_tree_bank import \\\n",
        "    StanfordSentimentTreeBankDatasetReader\n",
        "\n",
        "from realworldnlp.predictors import SentenceClassifierPredictor"
      ],
      "metadata": {
        "id": "0Mk6qVA1tOlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 128"
      ],
      "metadata": {
        "id": "dR-EdgC2viEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model in AllenNLP represents a model that is trained.\n",
        "class LstmClassifier(Model):\n",
        "    def __init__(self,\n",
        "                 embedder: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 vocab: Vocabulary,\n",
        "                 positive_label: str = '4') -> None:\n",
        "        super().__init__(vocab)\n",
        "        # We need the embeddings to convert word IDs to their vector representations\n",
        "        self.embedder = embedder\n",
        "\n",
        "        self.encoder = encoder\n",
        "\n",
        "        # After converting a sequence of vectors to a single vector, we feed it into\n",
        "        # a fully-connected linear layer to reduce the dimension to the total number of labels.\n",
        "        self.linear = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
        "                                      out_features=vocab.get_vocab_size('labels'))\n",
        "\n",
        "        # Monitor the metrics - we use accuracy, as well as prec, rec, f1 for 4 (very positive)\n",
        "        positive_index = vocab.get_token_index(positive_label, namespace='labels')\n",
        "        self.accuracy = CategoricalAccuracy()\n",
        "        self.f1_measure = F1Measure(positive_index)\n",
        "\n",
        "        # We use the cross entropy loss because this is a classification task.\n",
        "        # Note that PyTorch's CrossEntropyLoss combines softmax and log likelihood loss,\n",
        "        # which makes it unnecessary to add a separate softmax layer.\n",
        "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Instances are fed to forward after batching.\n",
        "    # Fields are passed through arguments with the same name.\n",
        "    def forward(self,\n",
        "                tokens: Dict[str, torch.Tensor],\n",
        "                label: torch.Tensor = None) -> torch.Tensor:\n",
        "        # In deep NLP, when sequences of tensors in different lengths are batched together,\n",
        "        # shorter sequences get padded with zeros to make them equal length.\n",
        "        # Masking is the process to ignore extra zeros added by padding\n",
        "        mask = get_text_field_mask(tokens)\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings = self.embedder(tokens)\n",
        "        encoder_out = self.encoder(embeddings, mask)\n",
        "        logits = self.linear(encoder_out)\n",
        "\n",
        "        # In AllenNLP, the output of forward() is a dictionary.\n",
        "        # Your output dictionary must contain a \"loss\" key for your model to be trained.\n",
        "        output = {\"logits\": logits}\n",
        "        if label is not None:\n",
        "            self.accuracy(logits, label)\n",
        "            self.f1_measure(logits, label)\n",
        "            output[\"loss\"] = self.loss_function(logits, label)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
        "        return {'accuracy': self.accuracy.get_metric(reset),\n",
        "                **self.f1_measure.get_metric(reset)}"
      ],
      "metadata": {
        "id": "4A1OlQUzPru0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = StanfordSentimentTreeBankDatasetReader()\n",
        "train_path = 'https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/train.txt'\n",
        "dev_path = 'https://s3.amazonaws.com/realworldnlpbook/data/stanfordSentimentTreebank/trees/dev.txt'"
      ],
      "metadata": {
        "id": "e3u7zld7QDgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = BucketBatchSampler(batch_size=32, sorting_keys=[\"tokens\"])\n",
        "train_data_loader = MultiProcessDataLoader(reader, train_path, batch_sampler=sampler)\n",
        "dev_data_loader = MultiProcessDataLoader(reader, dev_path, batch_sampler=sampler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0qfRuSFQ42R",
        "outputId": "2b18ba81-9997-40e5-b524-e5c56823dac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading instances: 0it [00:00, ?it/s]\n",
            "downloading:   0%|          | 0/2160058 [00:00<?, ?B/s]\u001b[A\n",
            "downloading:  10%|#         | 217088/2160058 [00:00<00:00, 2049951.41B/s]\u001b[A\n",
            "downloading: 100%|##########| 2160058/2160058 [00:00<00:00, 9574077.44B/s] \n",
            "loading instances: 8544it [00:03, 2751.80it/s]\n",
            "loading instances: 0it [00:00, ?it/s]\n",
            "downloading:   0%|          | 0/280825 [00:00<?, ?B/s]\u001b[A\n",
            "downloading: 100%|##########| 280825/280825 [00:00<00:00, 2482580.79B/s]\n",
            "loading instances: 1101it [00:00, 1238.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocabulary.from_instances(chain(train_data_loader.iter_instances(),\n",
        "                                        dev_data_loader.iter_instances()),\n",
        "                                  min_count={'tokens': 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-7UrRd5Q52L",
        "outputId": "468669be-95a8-4e87-ce71-a4cdf405f6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "building vocab: 9645it [00:00, 21195.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "embedding_dim=EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "G8sd-83gVZ6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embeddings = BasicTextFieldEmbedder({'tokens': token_embedding})"
      ],
      "metadata": {
        "id": "rXV5U75nWZ0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = PytorchSeq2VecWrapper(\n",
        "    torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True)\n",
        ")"
      ],
      "metadata": {
        "id": "VVgXg5DNW1ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader "
      ],
      "metadata": {
        "id": "UFET10kPoBRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aba480e-8db8-486a-9316-8b35e2eaa1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<allennlp_models.classification.dataset_readers.stanford_sentiment_tree_bank.StanfordSentimentTreeBankDatasetReader at 0x7ff7b546fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "etLO4HhHNa5R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}